---
layout: post
title:  "数据结构"
date:   2017-11-26 21:1:32 +0800
categories: jekyll update

# tags will also be used as html meta keywords.
tags:
  - algorithm
show_meta: true
comments: true
mathjax: true
gistembed: true
published: true
noindex: false
nofollow: false
use_math: true

---

詹令   
lealzhan@126.com    
2017.11.26   

# Contents
{:.no_toc}

* Will be replaced with the ToC, excluding the "Contents" header
{:toc}

# 线性结构

## Linear List 线性表


### 线性表的顺序表示

读,存 O(1)   
删除 O(n)   
插入 O(n)   



### 线性表的链式表示

## Stack 栈
- 定义： 限定仅在**表尾**进行插入或删除操作的线性表。
- Last in, First out 
- 表尾：栈顶 表头：栈底
- 出栈：删除元素 pop 
- 入栈：插入元素 push
- STL stack



### 栈的顺序表示
利用一组地址连续的存储单元依次存放自栈底到栈顶的数据元素，同时附设指针top指示栈顶元素在顺序栈中的位置。



### 栈的链式表示


### 实例
#### 括号匹配实时检测
```
[]() good
[(] wrong
[()] good
[(())) wrong
[(())] good
```

#### 迷宫求解
TODO

## Queue 队列

- First in, First out
- 队头 front 队尾 rear
- STL queue [[LINK](http://www.cplusplus.com/reference/queue/queue/)]

### 队列的顺序表示
 
### 队列的链式表示

[data, next] 


## Deque 双端队列


## Linked List 链表


## String 串

## 数组

## 广义表

# 非线性结构

## 树


>数据结构
>>树
>>>二叉树
>>>>平衡二叉树
>>>>>满二叉树


### 定义
**深度 Depth** 树中节点的最大层次称为树的深度。
**无序树** 树中节点的各子树看成从左到右是有次序的。 否则称为**有序树**。   
**森林 Forest** m(m>=0)棵互不相交的树的集合。   

### 二叉树 Binary Tree
- 二叉树是一种树，其每个节点至多有两颗子树，且子树有左右之分。   
- **满二叉树** 深度为k且有2^k-1个节点的二叉树。特点：每一层上的节点数都是最大节点数。   
- **完全二叉树** 深度为k的，有n个节点的二叉树，其每一个节点都与深度为k的**满二叉树**中编号从1到n的节点一一对应。      

	- 具有n节点的完全二叉树的深度为floor( log2(n) )+1

#### 二叉树的存储结构

##### 顺序存储结构

仅适用于完全二叉树

##### 链式存储结构
设计不同的节点结构可以构成不同形式的链式存储结构。
二叉树的节点包含 **指向左子树的指针 lchild**，**数据 data**，**指向右子树的指针 rchild**。有时为了方便查找节点的父节点，还会增加一个 **指向父节点的指针 parent**。

**二叉链表**的节点结构 lchild + data + rchild   
**三叉链表**的节点结构 lchild + data + parent +rchild   



#### 遍历二叉树

按照根节点的访问次序，可以分成先序遍历，中序遍历，后序遍历。
##### 先序遍历
步骤

- 访问根节点 
- 先序遍历左子树(递归地)
- 先序遍历右子树(递归地)

##### 中序遍历
步骤

- 中序遍历左子树
- 访问根节点 
- 中序遍历右子树

##### 后序遍历
步骤

- 访问根节点 
- 后序遍历左子树
- 后序遍历右子树



递归实现，非递归实现


##### 逐层遍历
从上往下，从左往右，按层次进行。

#### 线索二叉树

### 树和森林
#### 树的存储结构
##### 双亲表示法


##### 孩子表示法
##### 孩子兄弟表示法


#### 森林和二叉树的转换
#### 树和森林的遍历
#### 赫夫曼树及其应用

##### 定义

- 路径
- 路径长度
- 树的路径长度： 
- 节点的带权路径长度：从该节点k到树根之间的路径长度$$l_k$$与该节点上的权重$$w_k$$的乘积 $$l_kw_k$$   
- 树的带权路径长度: 树中所有叶子节点的带权路径长度之和 weighted path length $$ WPL = \sum_{k=1}^n w_kl_k $$
- 最优二叉树/赫夫曼树： 

##### 如何构造赫夫曼树


##### 应用



## 图 Graph

图貌似在一般的面试中，不太容易出现。 但是应该在实际中有很多应用。

- 之前做gauss sidel 迭代 求解线性方程组（布料模拟），如果要对其进行并行加速，则需要利用图着色算法，对点进行分类，分成几个内部点不相邻的点群，这样就可以进行并行更新了。（描述不清，待更新）
- 网格mesh和图有类似的地方

图是一种比线性表和树更为复杂的数据结构。

- 线性表的元素之间一种**线性关系**，即每个元素只有一个前驱和一个后继。
- 树结构的元素之间存在**层次关系**。
- 图结构的元素之间的关系是**任意**。

![](https://raw.githubusercontent.com/lealzhan/lealzhan.github.io/master/_pictures/2017-11-26-data-structure-graph-0.png)


### 定义

图中的数据元素称为**顶点 Vertex**。
 - **V**是顶点的有穷非空集合。   
 - **VR**是两个顶点之间的关系的集合
 - 如果 <v,w> 属于VR, 则<v,w>表示从v到w的一条弧(Arc)，v是弧尾(Tail)，w为弧头(Head or Initial Node).此时的图称为**有向图(Digraph)**

![]()

$$ G_1=(V_1,{A_1}) $$

其中$$ V_1 = {v_1,v_2,v_3,v_4} $$, $$ A_1 = {<v_1,v_2>,<v_1,v_3>,<v_3,v_4>,<v_4,v_1>} $$
 
 - 如果 <v,w>属于VR，且<w,v>属于VR，即VR是对称的，则可以用无序对(v,w)代替<w,v><v,w>这两个有序对。**无序对(v,w)**表示v和w之间的一条边(Edge), 此时的图称为**无向图(Undigraph)**。
 
![]()

$$ G_2=(V_2,{E_1}) $$

其中$$V_2 = {v_1,v_2,v_3,v_4,v_5}$$, $$E_2 = {(v_1,v_2),(v_1,v_4),(v_2,v_3),(v_2,v_5),(v_3,v_4),(v_3,v_5)}$$

 - **n**表示图中的顶点数目，**e**表示弧或边的数目。 
 - **(无向)完全图(completed graph)**：有$$ C_n^2 = \frac{n(n-1)}{2} $$条边的无向图.(任意两个顶点间都有边)
 - **有向完全图**：有$$ A_n^2 = n(n-1) $$条弧的有向图.(任意两个顶点间都有方向相反的两条弧)
 - 有很少条边或弧(<nlogn)的图称为**稀疏图(Sparse Graph)**，反之称为**稠密图(Dense Graph)**.
 - 边或弧有时有对应的数，称为 **权 weight**。可以用于表示一个顶点到另一个顶点的距离或耗费。这种_带权的图_通常称为**网(Network)**
 - **子图 subgraph**: $$有 G=(V,{E}), G'=(V',{E'}), 若 V'\subseteq V 且 E' \subseteq E， 则称 G'为G的子图 subgraph $$
 - 相邻 Adjacent: 对于无向图的边Edge的两个顶点，称这两个顶点互为相邻Adjacent关系。
 - 顶点v的**度degree**： 和顶点v相关联的边的数目，记为 TD(v)。

	- 以顶点v为头的弧的数目称为v的**入度(ingree)**，记为 ID(v)。
	- 以顶点v为尾的弧的数目称为v的**出度(outgree)**, 记为 OD(v)。
	- 顶点v的度 TD(v) = ID(v)+OD(v)
	- 一个有n个顶点，e条边或弧的图，记顶点$$v_i$$的度记为$$TD(v_i)$$, 则有如下关系：
	 	
 $$ e = \frac{1}{2} \sum _{i=1}^n TD(v_i) $$

 - 路径 Path：
 - 回路或环 Cycle: 第一个顶点和最后一个顶点相同的路径。
 - 简单路径： 序列中顶点不重复出现的路径
 - 简单回路/环： 除了第一个和最后一个顶点外，其余顶点不重复出现的回路
 - 在**无向图**G中，如果从顶点v到顶点v'有路径，则称v和v'是**连通**的。如果对于图中任意两个顶点都是连通的，则称G是**连通图(connected graph)**. 连通分量(connected component)指的是 无向图中极大连通子图。
 - 在**有向图**G中，如果对于任意一对$$v_i,v_j\in V, 从v_i到v_j, 从v_j到v_i$$都存在路径，则称G为**强连通图**。**强连通分量**指的是 有向图中极大连通子图。
 - 生成树
 - 生成森林
 - 

### 图的存储结构

#### 数组表示法

``` c
#define INFINITY INT_MAX
#define MAX_VERTEX_NUM 20
typedef enum {DG, Dn, UDG, UDN} GraphKind //{有向图，有向网，无向图，无向网}

typedef struct ArcCell
{
	VRType adj; //VRType是顶点关系类型。
	            //对无权图用0或者1表示相邻否；对带权图用权值类型。
	InfoType *info;  //该弧相关信息的指针
} ArcCell, AdjMatrix[MAX_VERTEX_NUM][MAX_VERTEX_NUM];

typedef struct
{
	VertexType vexs[MAX_VERTEX_NUMB]; //顶点向量
	AdjMatrix arcs;                   //邻接矩阵 
	int vexnum,arcnum;                //图的当前顶点数和弧数
	GraphKind kind;                   //图的种类标志
}MGraph;

```



**图的邻接矩阵**

- 无向图的邻接矩阵是对称的，因此一颗自存储上三角形或下三角形。
- 对于无向图，顶点$$v_i$$的度是邻接矩阵中的第i行或第i列的元素之和。
- 对于有向图，顶点$$v_i$$的出度是第i行元素之和，入度是第i列元素之和。


$$
G_1.arcs = 
 \left[
 \begin{matrix}
   0 & 1 & 1 & 0 \\
   0 & 0 & 0 & 0 \\
   0 & 0 & 0 & 1 \\
   1 & 0 & 0 & 0 \\
  \end{matrix}
  \right] \tag{x}
$$

$$
G_2.arcs = 
 \left[
 \begin{matrix}
   0 & 1 & 0 & 1 & 0 \\
   1 & 0 & 1 & 0 & 1 \\
   0 & 1 & 0 & 1 & 1\\
   1 & 0 & 1 & 0 & 0\\
   0 & 1 & 1 & 0 & 0\\
  \end{matrix}
  \right] \tag{x}
$$


**网的邻接矩阵**

网的邻接矩阵定义为：
$$ A[i][j] = \begin{cases} 
w_{i,j} && 若<v_i,v_j>或（v_i,v_j)\in VR\\ 
\infty && 反之
\end{cases} $$

![](https://raw.githubusercontent.com/lealzhan/lealzhan.github.io/master/_pictures/2017-11-26-data-structure-graph-1.png)


```c
Status CreateUDN(MGraph &G)
{

}

```

构造一个具有n个顶点和e条边的无向网G的时间复杂度$$O(n^2+e*n)$$,其中对邻接矩阵G.arcs的初始化耗费了$$O(n^2)$$的时间。








#### 邻接表 Adjancency List

- 邻接表是图的一种链式存储结构。
- 无向图有n个顶点，e条边，则其邻接表需要 n个头结点和2e个表节点。
	- 边稀疏($$e<<\frac{n(n-1)}{2}$$)的情况下，邻接表比邻接矩阵节省存储空间 
	- 无向图的邻接表中，顶点$$v_i$$的度恰为第i个链表的节点数。
- 有向图 ==> 邻接表，逆邻接表
- 建立邻接表的时间复杂度 
- 邻接表要查找任意两个顶点是否有边或弧相连，则需要搜索第i个或第j个链表，因此不如邻接矩阵方便。


![](https://raw.githubusercontent.com/lealzhan/lealzhan.github.io/master/_pictures/2017-11-26-data-structure-graph-2.png)


```c
//图的邻接表存储表示
#define MAX_VERTEX_NUM 20

//表节点 <== 头结点 指向的领边节点
typedef struct ArcNode
{
	int adjvex; //该弧所指向的顶点位置
	struct ArcNode *nextarc;//指向下一条弧的指针
	InfoType *info;//该弧相关信息的指针
}ArcNode;

//头结点  <== 图 直接指向的节点
typedef struct VNode 
{
	VextexType data; //顶点信息
	ArcNode *firstarc; //指向第一条依附于该顶点的弧的指针
}VNode, AdjList[MAX_VERTEX_NUM];

typedef struct
{
	AdjList vertices;
	int vexnum, arcnum; //图的当前顶点数和弧数
	int kind;//图的种类标志
}ALGraph; // Adjacency List Graph

```




#### 十字链表 Orthogonal List

- 十字链接表是图的另一种链式存储结构。



#### 邻接多重表 Adjacency Multilist

- 无向图的一种链式存储结构


``` c
//无向图的邻接多重表存储表示

#define MAX_VERTEX_NUM 20
typedef emnu{unvisited, visited} VisitIf;

typedef struct EBox   //edge
{
	VisitIf mark;     //访问标记（是否已被访问）
	int ivex,jvex;    //该边依附的两个顶点在图中的位置
	struct EBox *ilink, jlink;    //分别指向依附这两个顶点的下一条边
	InfoType *info;     //该边信息指针
}

typedef struct VexBox  //vertex
{
	VertexType data;    
	EBox *firstedge;    //指向第一条依附于该顶点的边
}

typedef struct
{
	VexBox adjmultist[MAX_VERTEX_NUM];
	int vexnum, edgenum;       //无向图的当前顶点数和边数
}AMLGraph;

```


### 图的遍历 Traversing graph
- 图的遍历： 从图的某一点出发，访遍图中其余顶点，且每个顶点仅被访问一次。
- 图的遍历算法是求图的连通性问题，拓扑排序和求解关键路径等算法的基础。
- 图的遍历比树的遍历要复杂的多
	- 原因：图的任何一个节点可能和其余的节点相邻，因此在访问某个顶点之后，沿某条路径搜索，可能又会回到该节点。
	- 为了避免同一顶点被多次访问，在遍历图的过程中，必须几下每个已访问过的顶点。  
	- 深度优先搜索和广度优先搜索对无向图和有向图都适用。
	- **遍历图的过程实质上是通过边或弧找邻接点的过程**，因此广度优先搜索和深度优先搜索的**时间复杂度相同**，两者不同之处仅仅在于**对顶点访问的顺序不同**。



#### 深度优先搜索 Depth First Search

- 是树的先根遍历的推广
- **过程**: 假设初始状态是图中所有顶点未曾被访问，则深度优先搜索可从图中某个顶点v出发，先访问此顶点，然后依次从该顶点未被访问的邻接点出发，深度优先遍历图，直至图中所有和v有路径相同的顶点都被访问到；若此时图中尚有顶点未被访问，则另选图中一个未曾被访问的顶点作为起点，重复上述过程，直至图中所有顶点都被访问到为止。（描述的不是很清楚）
- 对图的遍历实质上是对每个顶点**查找其邻接点**的过程，其耗时取决于所采用的存储结构。
	- 邻接矩阵：$$ O(n^2) $$
	- 邻接表：$$ O(n+e) $$


```c
Boolean visited([MAX]);      //访问标志数组
Status (*VisitFunc)(int v);  //函数变量//函数指针 ?

//从第v个顶点出发，递归地深度优先遍历图G
void DFS(Graph G, int v)
{
	visited[v] = True;
	VisitFunc(v);
	for(w=FirstAdjVex(G,v);w>=0;w=NextAdjVex(G,v,w))
	{	
		if(!visited[w])  //对v尚未访问的邻接顶点w递归调用DFS
			DFS(G,w);
	}
}

//对图G作深度优先遍历
void DFSTraverse(Graph G, Status (*Visit)(int v))
{
	VisitFunc = Visit;
	for(v=0;v<G.vexnum;++v) 
		visited[v] = False;       //访问标志数组初始化
	for(v=0;v<G.vexnum;++v)
		if(!visited[v]) DFS(G,v); //对尚未访问的顶点调用DFS
}

```


#### 广度优先搜索 Breadth Dirst Search
- 类似于树的按层次遍历的过程
- **广度优先搜索**：以v为起始点，由近及远，依次访问和v有路径相通且路径长度为1，2，...的顶点


``` c

void BFSTraverse(Graph G, Status(*Visit)(int v))
{
	//todo
}//BFSTraverse

```

### 图的连通性问题

#### 无向图的连通分量和生成树



### 有向无环图及其应用


### 最短路径




# 动态存储管理

### 概述

动态存储管理的基本问题 是 如何**分配**和**释放**内存。

系统每次分配给用户(不论大小)都是一个**地址连续**的内存区。

空间表有**目录**和**链表**两种形式。目录在操作系统中细讲。

空间表 亦被称为 存储池。   

### 可利用空间表及分配方法

空间表的三种结构形式

- 所有用户请求分配的存储量大小**相同**
- 所有用户请求分配的存储量大小有**固定几种规格**
- 所有用户请求分配的存储量大小**不固定**


#### 分配方法

分配一块大小为n的内存块。

##### 首次拟合法

- 从表头指针开始查找可利用空间表，将找到的第一个大小不小于n的空闲块的一部分分配给用户。


##### 最佳拟合法

- 将可利用空间表中一个不小于n且最接近n的空闲块的一部分分配给用户。
- 通常预先设定可利用空间表的结构按空间块的大小**自小到大**有序，这样需要查找链表，找到第一块大于n的空闲块进行分配，但在回收时，必须将释放的空间块插入到合适的位置上。
- 分配过程中，链表各个节点的空间大小差别趋向于**加大**

##### 最差拟合法

- 将可利用空间表中大小不小于n且是链表中最大的空闲块的一部分分配给用户。
- 通常预先设定可利用空间表的结构按空间块的大小**自大到小**有序。这样， 分配时无需查链表，只需将第一个节点分配给用户；回收内存时，需要查链表，将回收的内存块放在链表的适当位置。
- 分配过程中，链表各个节点的空间大小差别趋向于**均匀**


### 边界标识法 Boundary Tag Method

### 伙伴系统 Buddy System

### 无用单元收集

### 存储紧缩


# 查找

性能分析：   
衡量查找算法性能的好坏： “其关键字和给定值进行比较的记录个数的平均值”

>衡量一个算法好坏的三个标准   
>0. 时间复杂度： 衡量算法执行的时间量级   
>1. 空间复杂度： 衡量算法的数据结构所占存储与大连的附加存储   
>2. 算法的其他性能   

平均查找长度 Average Search Length （ASL）

$$ ASL = \sum_{i=1}^n P_i C_i $$

$$P_i$$:第i个记录被用户要求进行查找的频率。   
$$C_i$$:第i个记录被找到时，经过的比较次数。 

## 静态表查找
### 顺序表的查找

顺序表: 必需**逐个遍历**表去查找。

顺序表： 存储结构是 数组或顺序链表，数据本身是否排序没有规定。

监视哨： 免去每一步都要检测整个表是否查找完毕；进行一次查找的时间几乎减少一半？   


对于顺序表的查找，$$ C_i = n-i+1 $$   

$$ ASL = nP_1 +(n-1)P_2+...+2P_{n-1}+P_n $$

当 $$ P_1<=P_2<=...<=P_{n-1}<=P_n $$时，ASL最小。

所以实际情况中，一般   
（0）给每个记录附加一个访问频率域，对所有记录按照访问频率进行排序，使访问频率大的记录排在最先被查找到的位置。   
（1）将每次刚查找到的记录直接移到最先被查找到的位置。

note：移动记录 是否还是静态表？

顺序查找的优缺点：   
优点：简单，适用面广。   
缺点：平均查找长度大。特别是当n大时效率低。

顺序表查找平均长度为**查找失败时的平均长度**和**查找成功时的平均长度**之和.

$$ ASL_{ss} = \frac{1}{2}(n+1) + \frac{1}{2n} \sum_{i=1}^n (n-i+1) = \frac{3}{4}(n+1)$$

### 有序表的查找


有序表： 数据是排序的，访问某一个特定位置的数据的操作复杂度O(1)。

#### Binary Search 折半查找

数据是排序的，访问某一个特定位置的数据的操作复杂度O(1), 各个数据被查找的可能性**相等**。

折半查找适用于 存储结构是线性顺序存储(c的数组)(不适用于线性链式存储)，且数据要求是有序的。

##### 折半查找的模糊定义

先确定待查记录所在的范围（区间），然后逐步缩小范围直到找到或找不到该记录位置。    


```c
int search_binary(SSTable ST, KeyType key)
{
	//在ST有序表中折半查找关键字等于key的元素，若找到则函数值为该元素
	//在ST中的位置，否则为0
	low = 1; high = ST.length;
	while(low<high)
	{
		mid = (low+high)/2;
		if(EQ(key,ST.elem[mid].key)) return mid;
		else if(LT(key, ST.elem[mid].key)) high = mid-1;
		else low = mid+1;
	}
	return 0; //不存在
}
```

##### 性能分析

- **判定树** ： 描述查找过程的树：树中每个节点表示表中一个记录，节点中的值为该记录在表中的位置   
- ==> n个节点的判定树的深度等于n个节点的完全二叉树的深度 **log2(n)+1**    
- 折半查找在查找成功时进行比较的关键字个数最多不超过判定树的深度**log2(n)+1**    
- 折半查找在查找不成功时进行比较的关键字个数最多也不超过判定树的深度**log2(n)+1**    
- assume $$P_i = \frac{1}{n}$$, 基于判定树和ASL的定义，折半查找算法在查找成功时的平均查找长度 $$ ASL_{bs} = log_2(n+1)-1 $$
- assume $$P_i = \frac{1}{n}$$, 折半查找算法在查找不成功时的平均查找长度？    
- 折半查找只适用于有序表
- 折半查找只适用于顺序存储结构(c语言的数组？)

=> ASL = log2(n)


#### 斐波那契查找


#### 插值查找

对于关键字**均匀分布**的**比较长**的有序表，其**平均性能**优于 折半查找。


### 静态树表的查找

数据是排序的，访问某一个特定位置的数据的操作复杂度O(1), 各个数据被查找的可能性**不相等**。

- 构建静态最优查找树 过于费时，一般就是构建次优查找树。两者效率差距很少不超过3%.
- **构建次优查找树**(O(nlogn))，类似于二分法查找方式进行查找O(logn)。

### 索引顺序表的查找

- 索引表：   
- 分块有序：第二个子表的所有记录的关键字大于第一个子表的最大关键字。
- 查找步骤：先确定待查记录所在的子表，然后在块中顺序查找。由于索引表的关键字是有序的，可以基于顺序查找或折半查找确定子块；由于块中数据是随机排列的，因此只能在块中顺序查找。

每块含有的记录数量为 s

基于顺序查找确定子块   

$$ ASL_{bs} = \frac{1}{2}(\frac{n}{s}+s)+1$$
 
$$s=\sqrt{n}$$时，$$ASL_{bs}$$取最小值$$\sqrt{n}+1$$

基于折半查找确定子块    
$$ ASL_{bs} = log_2(\frac{n}{s}+1)+\frac{s}{2} $$



## 动态表查找

### 二叉排序树 Binary Sort Tree

**动态树表**: 树的结构通常不是一次生成的，而是在查找过程中，当树中不存在关键字等于给定值的节点时，在进行插入。

二叉排序树是一种动态树表。




#### 二叉排序树及其查找过程

二叉排序树可以为空，或者具有如下性质   
**性质**   
- 若它的左子树不空，则左子树上所有节点的值均小于它的根节点的值
- 若它的右子树不空，则右子树上所有节点的值均大于它的根节点的值
- 它的左右子树也分别为二叉排序树

一般取**二叉链表**作为二叉排序树的存储结构

##### 二叉排序树的查找

```c
BiTree SearchBST(BiTree T, KeyType key， BiTree f, BiTrtee &p)
{
	//在根指针T所指的二叉排序树中递归地查找器关键字等于key的数据元素，
	//若查找成功，则指针p指向该数据元素节点，并返回True；
	//若查找失败，则指针p指向查找路径上访问的最后一个节点，并返回False，指针f指向T的双亲，其初始值为NULL。
	
	if(!T) {p=f;return FALSE;}											//查找失败
	else if EQ(key,T->data.key){ p=T; return TRUE;}						//查找成功
	else if LT(key,T->data.key) return SearchBST(T->lchild,key,T,p);	//在左子树中继续查找
	else return SearchBST(T->rchild,key,T,p);							//在右子树中继续查找

}
```

#### 二叉排序树的插入和删除

**插入**: 新添加的节点一定是一个新添加的叶子节点，并且是查找不成功时查找路径上访问的最后一个节点的孩子节点。    

```c
Statuc InsertBST(BiTree &T, ElemType e)
{
	//当二叉排序树T中不存在关键字等于e.key的数据元素时，插入e并返回True，否则返回False
	if(!SearchBST(T, e.key, NULL, p)) //查找不成功 //若T为空，p=NULL, 若T不为空, p=查找路径的最后的一个节点
	{
		s = (BiTree)malloc(sizeof(BiNode));
		s->data = e; s->lchild = s->rchild=NULL;
		if(!p) T=s;										//T为空==> p=NULL ==> 被插节点*s为新的根节点
		else if LT(e.key, p->data.key) p->lchild = s;   //被插节点*s为左孩子
		else p->rchild = s;								//被插节点*s为右孩子
		return True;
	}
	else return False;//树中已有关键字相同的节点，不再插入
}//insert Binary Sort Tree

```

- 这样添加新节点时就不用去移动现有的节点。
- 对二叉排序树进行中序遍历，可以得到关键字的有序序列
- 对一个无序序列构建一个二叉排序树，然后对其中序遍历，就可以得到这个无序序列的有序序列。

**删除**： 

```c
Status DeleteBST(BiTree &T, KeyType key)
{
	//遍历元素，判断元素的key和查找的key的大小关系

	if(!T) return False;    //不存在关键字等于key的数据元素
	else
	{
		if(EQ(key,T->data.key)) {return Delete(T)};			//找到关键字等于key的数据元素，删除该元素
		else if(LT(key, T->data.key)) return DeleteBST(T->lchild,key);		//查找左子树
		else return DeleteBST(T->rchild,key);		//查找右子树
	}
}

Status Delete(BiTree &p)?todo
{
	//从二叉排序树中删除节点p，并重接它的左右子树
	if(!p->rchild)//右子树为空，重接左子树成为 被删除节点的父节点的左子树
	{
		q = p; p = p->lchild; free(q);
	}
	else if(!p->lchild)
	{
		q = p; p = p->rchild; free(q);
	}
	else
	{
	
	}
}

```
#### 二叉排序树的查找分析

- 含有n个节点的二叉排序树不唯一，二叉排序树的形态和待排序的关键字序列的排序状态有关
	- (45,24,53,12,37,93)  => BST depth=3
	- (12,24,37,45,53,93)  => BST depth=6
- 在二叉排序树查找关键字的过程的折半查找类似，和给定值比较的关键字次数，不超过二叉排序树的深度
- 最坏情况： 有序排序的关键字序列构成的二叉排序树 $$(n+1)/2$$
- 最好情况: 随机排序的关键字序列构成的二叉排序树 $$log_2n$$？


### 平衡二叉树 Balanced Binary Tree

平衡二叉树或者是一棵空树，或者具有如下性质：   
- 它的左右子树都是平衡二叉树
- 左子树和右子树的深度之差不差过1
- 可证明 ==》 平衡二叉树的深度为$$log_2 n$$  ==> 平均查找强度 $$log_2 n$$

平衡二叉树的实现方式有：   
- AVL
- 红黑树
- 替罪羊树
- Treap(Tree Heap)
- 伸展树

#### AVL
?

### B_树和B+树

### 键树


## 哈希表

- 之前的各种结构(**线性表，树**），**记录的键值** 和 **记录的存储位置**没有关系。 每次查找，都是进行一系列键值的比较操作，查找的效率依赖于比较的次数。
- **哈希表**： 
	- **哈希函数**： **记录的键值** 和 **记录的存储位置** 是**~~一一对应~~ 有一个确定的对应关系**的， 这个对应关系由**哈希函数**确定。查找时，只需确定是否存在键值，如果存在，就可以直接根据哈希函数确定存储位置。
	- **冲突**： 有一个确定的对应关系 而不是 一一对应，是因为哈希函数存在**不是一一对应的情况**，也就是两个不同的键值可能对应同一个记录的存储位置的情况，这种情况也称为 **冲突** **collision**。
	- 哈希函数为什么存在**冲突**（**不是一一对应的情况**）： 哈希函数是**记录的键值** 到 **记录的存储位置**的映射， 因为记录的键值集合一般远大于记录的存储位置的集合，因此**哈希函数是一个压缩映射**，这样冲突不可避免。
	- 构建哈希表时要设计 哈希函数和冲突处理方法
	- **哈希表**：根据设定的哈希函数H(key)和处理冲突的方法 将一组关键字映射到一个有限的连续的地址集(区间)上，并以关键字在地址集中的“像”作为记录在表中的存储位置，这种表便称为**哈希表**, 这一映射过程称为**哈希建表**或散列，所得的存储位置称为**哈希地址**或散列地址。

### 哈希函数的构造方法

**什么是好的哈希函数**    
均匀的哈希函数：使关键字经过哈希函数得到一个随机的地址，以便是一组关键字的哈希地址均匀的分布在整个地址区间中，从而减少冲突。

#### 直接定址法

取关键字或关键字的某个线性函数为哈希地址：   
$$ H(key) = key 或者 H(key) = a*key + b $$   
其中 a b为常数。

直接定址法的哈希地址集合和关键字集合的大小相同，因此不会有冲突，但是实际中也很少用到。


#### 数字分析法
假设关键字是以r为基的数（如以10为基的十进制数），并且哈希表中可能出现的关键字是事先知道的，则可去关键字的若干数位组成哈希地址。


#### 平方取中法
取关键字平方后的中间即为为哈希地址。因为一个数平方后的中间几位和树的每一位都相关。这是较为常用的一种方法。

#### 折叠法

#### 除留余数法
取关键字被某个不大于哈希表表长m的数p除后所得余数为哈希地址。即

$$ H(Key) = key MOD p, p<=m $$

- 最简单，最常用的构造哈希函数的方法
- 也可以先对关键字 key 进行操作（折叠，平方）后，再取mod。
- p若选择不好，易产生碰撞。p一般取质数或不包含小于20的质因数的合数。。。


#### 随机数法

选择一个随机函数，取关键字的随机函数值为它的哈希地址，即$$H(key)=random(key)$$，其中random为随机函数。通常，当关键字长度不等是采用此方法构造哈希函数较为恰当。

### 处理冲突的方法


#### 开放地址法

$$ H_i = (H(key)+d_i) MOD m     i = 1,2,...,k (k<=m-1) $$

其中 $$m$$ 为哈希表表长, $$d_i$$为递增序列，可有一下三种取法 
(1)线性探测再散列, $$d_i=1,2,3,...,m-1$$;    
(2) 二次探测再散列, $$ d_i = 1^2,-1^2,2^2, -2^2,...,k^2,-k^2 k<=m/2$$   
(3) 随机探测再散列, $$d_i$$取伪随机序列   

当 H(key)和现有哈希地址冲突，则逐次增加i(0,1,...)去求$$H_i$$,直到和现有哈希表地址不冲突。



#### 再哈希法

$$ H_i = RH_i(key) i = 1,2,...,k $$

$$RH_i$$均是不同的哈希函数，即在同义词产生地址冲突时计算另一个哈希函数地址，直到冲突不再发生。这种方法不易产生“聚集”，但增加了计算的时间。


#### 链地址法


#### 建立一个公共溢出区

假设哈希函数的值域为[0，m-1]，则设向量HashTable[0..m-1]为基本表，每个分量存放一个记录，另设向量OverTable[0..v]为溢出表。所有关键字和基本表中关键字为同义词的记录，不管它们由哈希函数得到的哈希地址是什么，一旦发生冲突，都填入溢出表。


### 哈希表的查找及其分析

给定K值，根据造表时设定的哈希函数求哈希地址，若表中此位置上没有记录，则查找不成功；否则比较关键字，若和给定值相等，则查找成功；否则根据冲突处理方法查找下一地址，直至哈希表中某个位置为空或者表中所填的关键字等于给定值为止。

或者说： 逐层去比较关键字

- 若哈希地址为空，返回false和地址；
- 若哈希地址的关键字不相等，再找下一层；
- 若哈希地址的关键字相等，返回true。

=> 代码实现?

```c

//--- 开放定址哈希表的存储结构---
int hashsize[] = {997,...};		//哈希表容量递增表，一个合适的素数序列
typedef struct{
	ElemType *elem;				//数据元素存储基址，动态分配数组? 
	int count;					//当前数据元素个数
	int sizeindex;				//hashsize[sizeindex]为当前容量
}Hashtable;

#define SUCCESS 1
#define UNSUCESS 0
#define DUPLICATE -1

Status SearchHash(HashTable H, KetType K, int &p, int &c)
{
	p = Hash(K);						//求得哈希地址
	while(H.elem[p].key!=NULLKEY &&		//该位置中填有记录
			!EQ(K,H.elem[p].key))		//并且关键字不相等
		collision(p,++c);				//求得下一探测地址p
	if EQ(K,H.elem[p].key)
		return SUCCESS;					//查找成功, p返回待查数据元素位置
	else return UNSUCCESS;				//查找不成功(H.elem[p].key == NULLKEY)
										//p 返回插入位置
}//SearchHash


```


#### **装填因子**

$$ a = \frac{表中填入的记录数}{哈希表的长度} $$


#### **平均查找长度**

成功

- 线性探测再散列

	$$ S_{nl} = \frac{1}{2}(1+\frac{1}{1-a}) $$ 

- 随机探测再散列

	$$ S_{nr} = -\frac{1}{a}ln(1-a) $$ 
	
- 链地址法

	$$ S_{nc} = 1 + \frac{a}{2} $$ 


不成功


- 线性探测再散列

	$$ S_{nl} = \frac{1}{2}(1+\frac{1}{(1-a)^2}) $$ 

- 随机探测再散列

	$$ S_{nr} = \frac{1}{1-a} $$ 
	
- 链地址法

	$$ S_{nc} = a + e^{-a} $$ 


哈希表的平均查找长度是a的函数，而不是n的函数。因此，不管n多大，总可以选择一个合适的装填因子以便将平均查找长度限定在一个范围内。

time complexity O(1)   
space complexity O(N)


# 内部排序

## 定义
- **排序**：将一个数据元素（或记录）的任意序列，重新排列成一个按关键字有序的序列。
- **内部排序和外部排序**：由于待排序的记录数量不同，使得排序过程中涉及的存储器不同，可将排序方法分为两大类：
	- **内部排序**，指的是待排序记录存放在计算机的随机存储其中进行的排序过程；
	- **外部排序**, 指的是待排序记录的数量很大，以致内存一次不能容纳全部记录，在排序过程中尚需对外存进行访问的排序过程。

内部排序方法很多，但并没有一种全能的算法可以应对所有的情况，需要根据实际情况选择不同排序算法。

通常在排序过程中，需要进行以下两类基本操作：

- 比较两个关键字的大小。 不可避免的操作。
- 将记录从一个位置移动到另一个位置。 可以通过改变记录存储方式来避免。

待排序记录有以下三种存储方式：

- 待排序记录存放在地址连续的一组存储单元上（**线性表的顺序存储结构**）。序列中相邻的两个记录的存储位置也是相邻。记录之间的次序关系由其存储位置决定，则实现排序必须借助改变记录存储位置。
- 待排序记录存放在**静态链表**中，记录之间的次序关系由指针只是，则实现排序不需要移动记录，仅需修改指针即可。
- 待排序记录本身存储在一组地址连续的存储单元，同时另设一个指示各个记录存储位置的地址向量，在排序过程中并不移动记录本身，而是移动地址向量中这些记录的地址，最后在排序之后再按照地址向量中的值调整记录的存储位置。

本文按照第一种方式存储，且记录的关键字均为整数。如下代码所示。

``` c
#define MAXSIZE 20		//一个用作示例的小顺序表的最大长度
typedef int KeyType 	//定义关键字类型为整数类型
typedef struct			
{
	KeyType key;		//关键字项
	InfoType otherinfo;	//其他数据项
}RedType;				//记录类型

typedef struct
{
	RedType r[MAXSIZE+1];	//r[0]闲置或用作哨兵单元
	int length;				//顺序表长度
}SqList;					//顺序表类型
```


## 插入排序

### 直接插入排序

直接插入排序是最简单的排序方法。它的基本操作是将一个记录插入到已排好序的有序表中，从而得到一个新的，记录加一的有序表。

``` c
void InsertSort()
{
	//对顺序表L作直接插入排序
	for(i = 2; i <= L.length; ++i)
	{
		if( LT( L.r[i].key, L.r[i-1].key ) )
		{
			L.r[0] = L.r[i];
			L.r[i] = L.r[i-1];
			for(j=i-2; LT(L.r[0].key,L.r[j].key); --j)
			{
				L.r[j+1] = L.r[j];
			}
			L.r[j+1] = L.r[0];
		}
	}
}//InsertSort
```


### 其他插入排序


### 基尔排序

## 快速排序
利用 ”交换“ 进行排序的方法。
### Bubble Sort

### Quick Sort
Quick Sort 是Bubble Sort的一种改进。   
分治
 
## 选择排序 Selection Sort
选择排序的基本思想是：每一趟在n-i+1(i=1,2,...,n-1)个记录中选取关键字最小的记录作为有序序列中的第i个记录。

### 简单选择排序
$$O(n^2)$$

### 树形选择排序 Tree Selection Sort
- 又称锦标赛排序 Tournament Sort。   
- 一趟：首先对n个记录的关键字进行两两比较，然后在其中n/2个较小者之间进行两两比较，如此重复，直到选出最小关键字的记录为止。
- 下一趟：选出一个最小关键字之后，将其更新为无穷大的数，更新树形结构。
- 每选择一个最小关键字需要$$O(log_2n)$$次比较操作， 则选择n个最小关键字的(对n个数进行排序)的时间复杂度 $$O(nlog_2n)$$
- 缺点：辅助存储空间多，和无穷大值进行多余的比较。。

### 堆排序 Heap Sort

#### 堆
将堆对应到一颗完全二叉树，则该树的非终端节点均不大于其左右孩子节点，则根节点元素为最大/小值。

```c
       96                1
	 /     \  
  83       27            2 
 /  \     /  
38   11  09              3

{96, 83, 27, 38, 11, 09}
 1   2   2   3   3    3  
```

#### 堆排序
如果在输出堆顶最小值之后，使得剩余n-1个元素的序列重建成一个堆，则得到n个元素中的次小值。如此反复，便能得到一个无序序列，这个过程称为堆排序。

#### 堆排序的两个问题
- 如何由一个无序序列建成一个堆?
- 如何在输出堆顶元素之后，调整剩余元素成为一个新的堆?

**筛选**：

```c
void HeapAdjust(HeapType &H, int s, int m)
{
	//已知H.r[s..m]中记录的关键字除H.r[s].key之外均满足堆的定义，本函
	//数调整H.r[s]的关键字，使H.r[s..m]成为一个大顶堆(对其中记录的关键字而言)
	rc = H.r[s];
	for( j = 2 * s; j <= m; j *= 2)   //沿key较大的孩子节点向下筛选
	{
		if( j < m && LT( H.r[j].key, H.r[j+1].key ) ) 
			++j;                //j为key较大的记录的下标
		if(!LT(rc.key, H.r[j].key)) 
			break;              //rc应插入在位置s上
		H.r[s] = H.r[j];
		s = j;
	}
	H.r[s] = rc;  //插入
}//HeapAdjust

void HeapSort(HeapType &H)
{
	for( i=H.length/2; i>0; --i )
		HeapAdjust( H, i, H.length); //把H.r[1..H.length]建成大顶堆
	for( i=H.length; i>1; --i)
	{
		H.r[1]<-->H.r[i];			  //将堆顶记录和当前未经
									  //排序子序列Hr[1..i]中
									  //最后一个元素相互交换
		HeapAdjust(H,1,i-1);		  //将H.r[1..i-1]重新调整为大顶堆
	}
}//HeapSort

```



时间复杂度   
$$O(nlog_2n)$$

## 归并排序
归并：将两个或两个以上的有序表组合成一个新的有序表。   
2路归并排序的核心操作是将一维数组中前后相邻的两个有序序列归并为一个有序序列。

## 基数排序 Radix Sorting



### 多关键字排序

### 链式基数排序

## 各种排序算法比较



-----------------------------------------



## Bubble Sort

Time Complexity: **O(N2)**   

```python
def bubble_sort(data_list):
	for i in range(len(data_list)-1):
		for j in range(i+1, len(data_list)-1):
			if( data_list[j] < data_list[i] ):
				data_list[j], data_list[i] = data_list[i], data_list[j]
	print ('bubble sort: ' + str(data_list))
```


## Quick Sort

Time Complexity: **O(NlogN)**   

```python



```


# 外部排序


# Reference

[] 严蔚敏, 吴伟民. 数据结构(C语言版)[M]. 清华大学出版社, 2016.   
[] Thomas H. Cormen. 算法导论，原书第三版 机械工业出版社, 2013.    
[] Robert Sedgewick. 算法，原书第四版, 人民邮电出版社.   
[] [http://www.cplusplus.com](http://www.cplusplus.com)    
[] 视频: 数据结构实例教程之第13讲.树和二叉树（遍历、线索二叉树）[[LINK](http://www.iqiyi.com/w_19rsauhjgt.html)]   
[] 俞勇. ACM国际大学生程序设计竞赛知识与入门[M]. 清华大学出版社, 2012.
[] 褚华. 软件设计师教程[M]. 清华大学出版社, 2014.




​​

